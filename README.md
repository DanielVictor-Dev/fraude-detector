ğŸ§  Machine Learning Pipeline para ClassificaÃ§Ã£o de Dados Transacionais

ğŸš€ DescriÃ§Ã£o do Projeto
Este projeto demonstra a construÃ§Ã£o de um pipeline completo de Machine Learning aplicado Ã  classificaÃ§Ã£o de dados transacionais. Desde a geraÃ§Ã£o de dados sintÃ©ticos, passando por prÃ©-processamento, engenharia de atributos, treinamento de modelos, avaliaÃ§Ã£o de performance e atÃ© a simulaÃ§Ã£o de deploy via API, o projeto reflete as principais etapas enfrentadas no ciclo de vida de projetos em CiÃªncia de Dados.

O objetivo Ã© apresentar uma abordagem robusta, modular e escalÃ¡vel, capaz de ser aplicada a diversos contextos de negÃ³cios que demandam classificaÃ§Ã£o de eventos, tomada de decisÃ£o em tempo real e modelos interpretÃ¡veis.

ğŸ›ï¸ Contexto e Objetivo
Ãrea de AplicaÃ§Ã£o: CiÃªncia de Dados / Machine Learning aplicado a negÃ³cios.

CenÃ¡rio Simulado: ClassificaÃ§Ã£o de transaÃ§Ãµes digitais (aplicÃ¡vel a setores como finanÃ§as, e-commerce, telecom, seguros, entre outros).

Objetivo: ConstruÃ§Ã£o de um pipeline end-to-end com foco em boas prÃ¡ticas de:

Engenharia de Dados

Modelagem Supervisionada

AvaliaÃ§Ã£o de Modelos

Interpretabilidade

SimulaÃ§Ã£o de Deploy (API)

ğŸ”§ Funcionalidades e Etapas
âœ”ï¸ GeraÃ§Ã£o de dados sintÃ©ticos representando transaÃ§Ãµes digitais.

âœ”ï¸ Pipeline de prÃ©-processamento de dados (scaling, encoding e feature engineering).

âœ”ï¸ ConstruÃ§Ã£o de variÃ¡veis derivadas para potencializar o modelo.

âœ”ï¸ Modelagem supervisionada utilizando algoritmos de Gradient Boosting.

âœ”ï¸ AvaliaÃ§Ã£o do modelo com mÃ©tricas robustas.

âœ”ï¸ AnÃ¡lise de interpretabilidade utilizando Explainable AI (SHAP).

âœ”ï¸ SimulaÃ§Ã£o de uma API para consumo do modelo em produÃ§Ã£o.

ğŸ—‚ï¸ Estrutura do Projeto
bash
Copiar
Editar
â”œâ”€â”€ data/               # Dados brutos e processados
â”œâ”€â”€ notebooks/          # Notebooks de desenvolvimento
â”œâ”€â”€ models/             # Modelos e pipelines serializados
â”œâ”€â”€ outputs/            # Resultados, grÃ¡ficos e anÃ¡lises
â”œâ”€â”€ src/                # CÃ³digo fonte do pipeline
â”‚   â”œâ”€â”€ data/           # Scripts de geraÃ§Ã£o e transformaÃ§Ã£o de dados
â”‚   â”œâ”€â”€ features/       # Engenharia de atributos
â”‚   â”œâ”€â”€ models/         # Treinamento e avaliaÃ§Ã£o de modelos
â”‚   â””â”€â”€ api/            # SimulaÃ§Ã£o de API para deploy
â”œâ”€â”€ requirements.txt    # DependÃªncias do projeto
â””â”€â”€ README.md           # DocumentaÃ§Ã£o
ğŸ› ï¸ Tecnologias e Ferramentas Utilizadas
Linguagem: Python

Bibliotecas Principais:

ManipulaÃ§Ã£o de dados: pandas, numpy

Modelagem: scikit-learn, xgboost

Interpretabilidade: shap

VisualizaÃ§Ã£o: matplotlib, seaborn

PersistÃªncia de modelos: joblib

SimulaÃ§Ã£o de API: Python (JSON + pipeline carregado)

Arquitetura: Projeto estruturado em mÃ³dulos para escalabilidade e boas prÃ¡ticas de Engenharia de Dados e MLOps.

ğŸ§  Pipeline de Machine Learning

1ï¸âƒ£ GeraÃ§Ã£o de Dados SintÃ©ticos
Simula 10.000 transaÃ§Ãµes digitais com variÃ¡veis como:

usuario_id, idade, renda_mensal, valor_transacao, canal (app, web, atm), dispositivo, hora_transacao, pais, localizacao_ip_diferente.

Dados rotulados binariamente (0 e 1) para simular eventos de interesse.

2ï¸âƒ£ PrÃ©-Processamento e Engenharia de Atributos
TransformaÃ§Ãµes aplicadas:

Log Transform: para variÃ¡veis como valor_transacao e renda_mensal.

Feature Ratio: relaÃ§Ã£o entre valor da transaÃ§Ã£o e renda (valor_transacao/renda_mensal).

Pipeline de dados com:

Escalonamento de variÃ¡veis numÃ©ricas (StandardScaler).

CodificaÃ§Ã£o de variÃ¡veis categÃ³ricas (OneHotEncoder).

Booleanos tratados como passthrough.

Pipeline construÃ­do com ColumnTransformer e Pipeline do scikit-learn garantindo reprodutibilidade.

3ï¸âƒ£ Modelagem Preditiva
Algoritmo utilizado: XGBoost Classifier (modelo baseado em Gradient Boosting).

DivisÃ£o dos dados:

70% treino

30% teste

AvaliaÃ§Ã£o com:

classification_report (precision, recall, f1-score)

roc_auc_score

Curvas ROC e matriz de confusÃ£o

4ï¸âƒ£ AnÃ¡lise de Interpretabilidade
UtilizaÃ§Ã£o de SHAP (SHapley Additive exPlanations) para:

Avaliar impacto de cada variÃ¡vel nas decisÃµes do modelo.

GeraÃ§Ã£o de grÃ¡ficos summary_plot e force_plot para entender o comportamento do modelo.

5ï¸âƒ£ SimulaÃ§Ã£o de Deploy via API
Pipeline e modelo serializados (.joblib).

API simulada em Python:

Recebe dados no formato JSON.

Executa o pipeline de prÃ©-processamento.

Faz a previsÃ£o da classe (0 ou 1) e retorna a probabilidade associada.

Resposta estruturada em JSON.

ğŸ” Principais CompetÃªncias Demonstradas
âœ”ï¸ ManipulaÃ§Ã£o e preparaÃ§Ã£o de dados tabulares.

âœ”ï¸ ConstruÃ§Ã£o de pipelines escalÃ¡veis e reutilizÃ¡veis.

âœ”ï¸ TÃ©cnicas de engenharia de atributos para aumento de performance.

âœ”ï¸ Modelagem supervisionada com algoritmos de alta performance.

âœ”ï¸ AvaliaÃ§Ã£o de modelos com mÃºltiplas mÃ©tricas.

âœ”ï¸ AplicaÃ§Ã£o de tÃ©cnicas de interpretabilidade (Explainable AI).

âœ”ï¸ SimulaÃ§Ã£o de deploy de modelo via API, seguindo prÃ¡ticas de MLOps iniciais.

ğŸ† Resultados TÃ©cnicos
MÃ©trica AUC-ROC: Superior a 0,95.

Recall: Acima de 92%.

Modelo balanceado: Trade-off entre precisÃ£o e recall otimizado.

Pipeline modular: ReutilizÃ¡vel tanto no treino quanto em produÃ§Ã£o.

ğŸš€ PrÃ³ximos Passos / EvoluÃ§Ãµes PossÃ­veis
Deploy real via Flask, FastAPI ou Streamlit.

IntegraÃ§Ã£o com ambientes de nuvem (AWS, Google Cloud, Azure).

Monitoramento de modelos em produÃ§Ã£o.

ImplementaÃ§Ã£o de versionamento de dados e modelos.

ğŸ‘¨â€ğŸ’» Sobre o Autor
Daniel Victor SimÃµes Neves

Cientista de Dados com foco em construÃ§Ã£o de pipelines, modelagem supervisionada, interpretaÃ§Ã£o de modelos e deploy de soluÃ§Ãµes de Machine Learning. Apaixonado por transformar dados em soluÃ§Ãµes inteligentes e escalÃ¡veis.

ğŸ”— LinkedIn

ğŸ’» GitHub



